# -*- coding: utf-8 -*-
"""kidney-classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sCrNFAQ_kCAGGOwazOxZh_lDekPy-eiX
"""

# Step 1: Download the ZIP file from Google Drive using gdown
!gdown --id 1vlhZ5c7abUKF8xXERIw6m9Te8fW7ohw3

# Step 2: Unzip the dataset
import zipfile
with zipfile.ZipFile('/content/kidney-ct-scan-image.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/dataset')

# Step 3: Check the folder structure (optional)
import os
for root, dirs, files in os.walk('/content/dataset'):
    level = root.replace('/content/dataset', '').count(os.sep)
    indent = ' ' * 4 * level
    print(f'{indent}{os.path.basename(root)}/')
    subindent = ' ' * 4 * (level + 1)
    for f in files[:5]:  # show only first 5 files per folder
        print(f'{subindent}{f}')
    if len(files) > 5:
        print(f'{subindent}... ({len(files)} files)')

# Step 4: Train model
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Parameters
data_dir = "/content/dataset/kidney-ct-scan-image"
image_size = (224, 224)
batch_size = 16
epochs = 15

# Data generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
)

train_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Load and freeze base model
base_model = VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
for layer in base_model.layers[:10]:
    layer.trainable = False

# Add classification head
x = Flatten()(base_model.output)
x = Dense(2, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=x)

# Compile
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
history=model.fit(train_generator, validation_data=val_generator, epochs=epochs)

# Save model as model.h5
model.save("model.h5")

import tensorflow as tf

# Load your Keras model
model = tf.keras.models.load_model("model.h5")

# Convert to TensorFlow Lite format
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the converted model
with open("model.tflite", "wb") as f:
    f.write(tflite_model)

print(train_generator.class_indices)

# Final loss and accuracy
train_loss = history.history['loss'][-1]
train_acc = history.history['accuracy'][-1]
val_loss = history.history['val_loss'][-1]
val_acc = history.history['val_accuracy'][-1]

print(f"\nðŸ“Š Final Training Loss: {train_loss:.4f}")
print(f"âœ… Final Training Accuracy: {train_acc:.4f}")
print(f"\nðŸ“‰ Final Validation Loss: {val_loss:.4f}")
print(f"ðŸŽ¯ Final Validation Accuracy: {val_acc:.4f}")

